{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2538b4c-4f87-43e4-8f24-fab1935dc4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Churn Data Loaded Successfully\n",
      "  CustomerID  Tenure  MonthlyCharges  TotalCharges        Contract  \\\n",
      "0     C00001       6              64          1540        One year   \n",
      "1     C00002      21             113          1753  Month-to-month   \n",
      "2     C00003      27              31          1455        Two year   \n",
      "3     C00004      53              29          7150  Month-to-month   \n",
      "4     C00005      16             185          1023        One year   \n",
      "\n",
      "      PaymentMethod PaperlessBilling  SeniorCitizen  Churn  \n",
      "0       Credit Card               No              1      0  \n",
      "1  Electronic Check              Yes              1      0  \n",
      "2       Credit Card               No              1      0  \n",
      "3  Electronic Check               No              1      0  \n",
      "4  Electronic Check               No              1      0  \n",
      "Churn data shape: (500, 9)\n",
      "\n",
      "Sales Data Loaded Successfully\n",
      "         Date     Product  Quantity  Price Customer_ID Region  Total_Sales\n",
      "0  2024-01-01       Phone         7  37300     CUST001   East       261100\n",
      "1  2024-01-02  Headphones         4  15406     CUST002  North        61624\n",
      "2  2024-01-03       Phone         2  21746     CUST003   West        43492\n",
      "3  2024-01-04  Headphones         1  30895     CUST004   East        30895\n",
      "4  2024-01-05      Laptop         8  39835     CUST005  North       318680\n",
      "Sales data shape: (100, 7)\n",
      "Sales columns: ['Date', 'Product', 'Quantity', 'Price', 'Customer_ID', 'Region', 'Total_Sales']\n",
      "\n",
      "--- DESCRIPTIVE STATISTICS (Sales Data) ---\n",
      "              Date Product    Quantity         Price Customer_ID Region  \\\n",
      "count          100     100  100.000000    100.000000         100    100   \n",
      "unique         100       5         NaN           NaN         100      4   \n",
      "top     2024-01-01  Tablet         NaN           NaN     CUST001  North   \n",
      "freq             1      26         NaN           NaN           1     28   \n",
      "mean           NaN     NaN    4.780000  25808.510000         NaN    NaN   \n",
      "std            NaN     NaN    2.588163  13917.630242         NaN    NaN   \n",
      "min            NaN     NaN    1.000000   1308.000000         NaN    NaN   \n",
      "25%            NaN     NaN    2.750000  14965.250000         NaN    NaN   \n",
      "50%            NaN     NaN    5.000000  24192.000000         NaN    NaN   \n",
      "75%            NaN     NaN    7.000000  38682.250000         NaN    NaN   \n",
      "max            NaN     NaN    9.000000  49930.000000         NaN    NaN   \n",
      "\n",
      "          Total_Sales  \n",
      "count      100.000000  \n",
      "unique            NaN  \n",
      "top               NaN  \n",
      "freq              NaN  \n",
      "mean    123650.480000  \n",
      "std     100161.085275  \n",
      "min       6540.000000  \n",
      "25%      39517.500000  \n",
      "50%      97955.500000  \n",
      "75%     175792.500000  \n",
      "max     373932.000000  \n",
      "\n",
      "Median Values:\n",
      "Quantity           5.0\n",
      "Price          24192.0\n",
      "Total_Sales    97955.5\n",
      "dtype: float64\n",
      "\n",
      "Mode Values:\n",
      "Date           2024-01-01\n",
      "Product            Tablet\n",
      "Quantity              4.0\n",
      "Price                1308\n",
      "Customer_ID       CUST001\n",
      "Region              North\n",
      "Total_Sales          6540\n",
      "Name: 0, dtype: object\n",
      "Warning: 'Sales' column not found\n",
      "Insufficient numeric columns for correlation\n",
      "\n",
      "--- HYPOTHESIS TEST RESULTS ---\n",
      "\n",
      "'Revenue' column not found for CI calculation\n",
      "\n",
      "Missing columns for regression (need Marketing_Spend and Revenue)\n",
      "\n",
      "--- BUSINESS INSIGHTS & RECOMMENDATIONS ---\n",
      "\n",
      "Recommendations:\n",
      "- Increase marketing spend in high-performing regions\n",
      "- Use regression model for revenue forecasting\n",
      "- Monitor regional differences via ANOVA\n",
      "- Apply A/B testing for campaigns\n",
      "\n",
      "PROJECT COMPLETED SUCCESSFULLY\n",
      "Generated files: hypothesis_tests_results.txt, sales_distribution.png, correlation_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Statistical Business Analysis Project - CORRECTED VERSION\n",
    "# ============================================================\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: Import Required Libraries\n",
    "# -------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend to avoid plot errors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 2: Load Given Data Files (with error handling)\n",
    "# -------------------------------\n",
    "try:\n",
    "    churn_df = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\customer_churn (1).csv\")\n",
    "    print(\"Customer Churn Data Loaded Successfully\")\n",
    "    print(churn_df.head())\n",
    "    print(f\"Churn data shape: {churn_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    churn_df = None\n",
    "    print(\"Customer Churn file not found - skipping churn analysis\")\n",
    "\n",
    "try:\n",
    "    sales_df = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\sales_data (5).csv\")\n",
    "    print(\"\\nSales Data Loaded Successfully\")\n",
    "    print(sales_df.head())\n",
    "    print(f\"Sales data shape: {sales_df.shape}\")\n",
    "    print(\"Sales columns:\", sales_df.columns.tolist())\n",
    "except FileNotFoundError:\n",
    "    sales_df = None\n",
    "    print(\"Sales data file not found - analysis will skip sales sections\")\n",
    "\n",
    "# Proceed only if sales_df is loaded\n",
    "if sales_df is None:\n",
    "    print(\"ERROR: Sales data required for analysis. Please provide sales_data (5).csv\")\n",
    "    exit()\n",
    "\n",
    "# -------------------------------\n",
    "# DAY 1: DESCRIPTIVE STATISTICS\n",
    "# -------------------------------\n",
    "print(\"\\n--- DESCRIPTIVE STATISTICS (Sales Data) ---\")\n",
    "print(sales_df.describe(include='all'))  # include='all' for better overview\n",
    "\n",
    "print(\"\\nMedian Values:\")\n",
    "print(sales_df.select_dtypes(include=[np.number]).median())  # Only numeric, avoids FutureWarning\n",
    "\n",
    "print(\"\\nMode Values:\")\n",
    "mode_df = sales_df.mode()\n",
    "if not mode_df.empty:\n",
    "    print(mode_df.iloc[0])\n",
    "else:\n",
    "    print(\"No mode computed (all unique values)\")\n",
    "\n",
    "# -------------------------------\n",
    "# DAY 2: DATA DISTRIBUTION ANALYSIS\n",
    "# -------------------------------\n",
    "if 'Sales' in sales_df.columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(data=sales_df, x=\"Sales\", kde=True)\n",
    "    plt.title(\"Sales Distribution\")\n",
    "    plt.xlabel(\"Sales\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.savefig(\"sales_distribution.png\")  # Save instead of show()\n",
    "    plt.close()  # Close to free memory\n",
    "    print(\"Sales distribution plot saved as 'sales_distribution.png'\")\n",
    "\n",
    "    # Normality Test (sample if large dataset)\n",
    "    sales_sample = sales_df[\"Sales\"].dropna()\n",
    "    if len(sales_sample) <= 5000:\n",
    "        stat, p_value = stats.shapiro(sales_sample)\n",
    "    else:\n",
    "        stat, p_value = stats.kstest(sales_sample, 'norm', args=(sales_sample.mean(), sales_sample.std()))\n",
    "    print(\"\\nNormality Test p-value:\", p_value)\n",
    "\n",
    "    if p_value > 0.05:\n",
    "        print(\"Sales data appears normally distributed (fail to reject null)\")\n",
    "    else:\n",
    "        print(\"Sales data is NOT normally distributed (reject null)\")\n",
    "else:\n",
    "    print(\"Warning: 'Sales' column not found\")\n",
    "\n",
    "# -------------------------------\n",
    "# DAY 3: CORRELATION ANALYSIS\n",
    "# -------------------------------\n",
    "numeric_cols = ['Sales', 'Marketing_Spend', 'Revenue']\n",
    "available_cols = [col for col in numeric_cols if col in sales_df.columns]\n",
    "if len(available_cols) >= 2:\n",
    "    corr_matrix = sales_df[available_cols].corr(numeric_only=True)\n",
    "    print(\"\\nCorrelation Matrix:\")\n",
    "    print(corr_matrix)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"correlation_heatmap.png\")\n",
    "    plt.close()\n",
    "    print(\"Correlation heatmap saved as 'correlation_heatmap.png'\")\n",
    "else:\n",
    "    print(\"Insufficient numeric columns for correlation\")\n",
    "\n",
    "# -------------------------------\n",
    "# DAY 4: HYPOTHESIS TESTING\n",
    "# -------------------------------\n",
    "results = []\n",
    "\n",
    "if 'Sales' in sales_df.columns:\n",
    "    # Test 1: One-sample t-test (skip if NaNs)\n",
    "    sales_clean = sales_df[\"Sales\"].dropna()\n",
    "    if len(sales_clean) > 0:\n",
    "        t1_stat, t1_p = stats.ttest_1samp(sales_clean, 50000)\n",
    "        results.append(f\"One-sample t-test p-value: {t1_p:.4f}\")\n",
    "\n",
    "    # Test 2: Independent t-test (North vs South) - check if regions exist\n",
    "    if 'Region' in sales_df.columns:\n",
    "        north_sales = sales_df[sales_df[\"Region\"] == \"North\"][\"Sales\"].dropna()\n",
    "        south_sales = sales_df[sales_df[\"Region\"] == \"South\"][\"Sales\"].dropna()\n",
    "        if len(north_sales) > 1 and len(south_sales) > 1:\n",
    "            t2_stat, t2_p = stats.ttest_ind(north_sales, south_sales, equal_var=False)  # Welch's t-test safer\n",
    "            results.append(f\"Independent t-test p-value (North vs South): {t2_p:.4f}\")\n",
    "\n",
    "        # Test 3: ANOVA (All regions)\n",
    "        groups = [group[\"Sales\"].dropna() for _, group in sales_df.groupby(\"Region\") if len(group[\"Sales\"].dropna()) > 1]\n",
    "        if len(groups) > 1:\n",
    "            anova_stat, anova_p = stats.f_oneway(*groups)\n",
    "            results.append(f\"ANOVA p-value (regions): {anova_p:.4f}\")\n",
    "\n",
    "print(\"\\n--- HYPOTHESIS TEST RESULTS ---\")\n",
    "for r in results:\n",
    "    print(r)\n",
    "\n",
    "# Save hypothesis results\n",
    "with open(\"hypothesis_tests_results.txt\", \"w\") as f:\n",
    "    for r in results:\n",
    "        f.write(r + \"\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# DAY 5: CONFIDENCE INTERVALS\n",
    "# -------------------------------\n",
    "if 'Revenue' in sales_df.columns:\n",
    "    revenue_clean = sales_df[\"Revenue\"].dropna()\n",
    "    if len(revenue_clean) > 0:\n",
    "        mean_rev = revenue_clean.mean()\n",
    "        std_rev = revenue_clean.std()\n",
    "        n = len(revenue_clean)\n",
    "        z = stats.norm.ppf(0.975)\n",
    "        margin_error = z * (std_rev / np.sqrt(n))\n",
    "        ci_lower = mean_rev - margin_error\n",
    "        ci_upper = mean_rev + margin_error\n",
    "        print(f\"\\n95% Confidence Interval for Revenue (n={n}):\")\n",
    "        print(f\"Lower Bound: {ci_lower:.2f}\")\n",
    "        print(f\"Upper Bound: {ci_upper:.2f}\")\n",
    "else:\n",
    "    print(\"\\n'Revenue' column not found for CI calculation\")\n",
    "\n",
    "# -------------------------------\n",
    "# DAY 6: REGRESSION ANALYSIS\n",
    "# -------------------------------\n",
    "if all(col in sales_df.columns for col in ['Marketing_Spend', 'Revenue']):\n",
    "    X = sales_df[[\"Marketing_Spend\"]].dropna()\n",
    "    y = sales_df.loc[X.index, \"Revenue\"]  # Align indices\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    print(\"\\n--- REGRESSION SUMMARY ---\")\n",
    "    print(model.summary())\n",
    "    print(f\"\\nR-squared Value: {model.rsquared:.4f}\")\n",
    "else:\n",
    "    print(\"\\nMissing columns for regression (need Marketing_Spend and Revenue)\")\n",
    "\n",
    "# -------------------------------\n",
    "# DAY 7: BUSINESS INSIGHTS (using available corr_matrix)\n",
    "# -------------------------------\n",
    "print(\"\\n--- BUSINESS INSIGHTS & RECOMMENDATIONS ---\")\n",
    "\n",
    "corr_matrix_safe = globals().get('corr_matrix', pd.DataFrame())\n",
    "if 'Marketing_Spend' in corr_matrix_safe.index and 'Revenue' in corr_matrix_safe.columns:\n",
    "    corr_val = corr_matrix_safe.loc[\"Marketing_Spend\", \"Revenue\"]\n",
    "    if abs(corr_val) > 0.6:\n",
    "        print(\"✔ Strong relationship between marketing spend and revenue (|r| > 0.6)\")\n",
    "\n",
    "if results:  # Use saved p-values\n",
    "    for r in results:\n",
    "        if 't1' in r.lower() and float(r.split(':')[1]) <= 0.05:\n",
    "            print(\"✔ Average sales significantly differ from 50,000 target\")\n",
    "        if 'anova' in r.lower() and float(r.split(':')[1]) <= 0.05:\n",
    "            print(\"✔ Sales significantly vary across regions\")\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "print(\"- Increase marketing spend in high-performing regions\")\n",
    "print(\"- Use regression model for revenue forecasting\")\n",
    "print(\"- Monitor regional differences via ANOVA\")\n",
    "print(\"- Apply A/B testing for campaigns\")\n",
    "\n",
    "print(\"\\nPROJECT COMPLETED SUCCESSFULLY\")\n",
    "print(\"Generated files: hypothesis_tests_results.txt, sales_distribution.png, correlation_heatmap.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a577f-7148-41a9-be1b-6b5360677487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
